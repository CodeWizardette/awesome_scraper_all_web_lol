# awesome_scraper_all_web_lol

This project is a web scraper that extracts data from multiple websites.

## Description

The web scraper is built using Python and utilizes the following libraries:
- `requests` for sending HTTP requests
- `BeautifulSoup` for parsing HTML
- `csv` for handling CSV files
- `time` for adding delays between requests
- `logging` for logging errors
- `random` for generating random delays
- `requestium` for handling proxy rotation

The scraper visits various websites, generates URLs based on domain and extension combinations, and extracts specific data from the HTML using CSS selectors.

## Contributing

Contributions are welcome! If you have any suggestions, bug reports, or feature requests, please open an issue or submit a pull request.

## License

This project is licensed under the [MIT License](LICENSE).

